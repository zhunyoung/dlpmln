{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../\")\n",
    "from dlpmln import DeepLPMLN\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import time\n",
    "from network import FC\n",
    "from dataGen import KsData\n",
    "import random\n",
    "from IPython.display import display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a simple version of the knapsack problem, where each item is associated with a\n",
    "value and the task is to choose a subset of the items that maximizes the sum of the values of\n",
    "the items. We assume there are 10 items with the same weight 2, and the capacity of the\n",
    "knapsack is 15. For example,\n",
    "\n",
    "            [2,7,3,5,2,3,8,2,1,5][1,2,3,4,5,6,9]\n",
    "\n",
    "is a labeled example such that the first list specifies the values of the 10 items and the second\n",
    "list is a solution that specifies the indices of the items to be put into the knapsack. Since the\n",
    "capacity of the knapsack is fixed to be 15 and each item has weight 2, one can infer that the\n",
    "solutions always contain 7 items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dprogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprogram='''\n",
    "% define k \n",
    "#const k = 7.\n",
    "\n",
    "topk(k).\n",
    "nn(m(k,10), in, [t,f]) :- topk(k).\n",
    "\n",
    "% we make a mistake if the total weight of the chosen items exceeds maxweight \n",
    "mistake :- #sum{1, I : in(k,I,t)} > k.\n",
    "'''\n",
    "\n",
    "dprogram_test='''\n",
    "% define k \n",
    "#const k = 7.\n",
    "\n",
    "topk(k).\n",
    "% we make a mistake if the total weight of the chosen items exceeds maxweight \n",
    "mistake :- #sum{1, I : in(k,I,t)} > k.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format\n",
    "\n",
    "### dataset\n",
    "\n",
    "A KsData object with 6 attributes: train_data, test_data, valid_data, train_labels,  \n",
    "\n",
    "test_labels, valid_labels  \n",
    "train_data is an numpy array of size (1800, 10). It consists of 1800 data as follows \n",
    "\n",
    "        [\n",
    "        data,\n",
    "        ...,\n",
    "        data\n",
    "        ]\n",
    "        \n",
    "where data is a vector (numpy array) of length 10. For example, the data shown below  \n",
    "\n",
    "        [2 2 1 3 1 2 8 1 5 1]\n",
    "        \n",
    "defines the 10 values of the 10 items.  \n",
    "train_labels is an numpy array of size (1800, 10). It consists of 1800 label as follows.  \n",
    "\n",
    "        [\n",
    "        label,\n",
    "        ...,\n",
    "        label\n",
    "        ]\n",
    "\n",
    "where label is a vector (numpy array) of length 24. For example, the label shown below  \n",
    "\n",
    "        [0 0 1 0 0 0 0 0 0 0]\n",
    "\n",
    "means that the item 2 is chosen to be put into the knapsack.  \n",
    "test_data is a numpy array of size (600, 10).   \n",
    "valid_data is a numpy array of size (600, 10).  \n",
    "test_labels is a numpy array of size (600, 10).  \n",
    "valid_labels is a numpy array of size (600, 10).  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network (MLP) Structure: (10, 50, 50, 50, 50, 50, 10)\n"
     ]
    }
   ],
   "source": [
    "m = FC(10, *[50, 50, 50, 50, 50], 10)\n",
    "\n",
    "nnMapping = {'m': m}\n",
    "\n",
    "optimizer = {'m':torch.optim.Adam(m.parameters(), lr=0.001)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DeepLPMLN Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlpmlnObj = DeepLPMLN(dprogram, nnMapping, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataList and obsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KsData(\"data/data.txt\",10)\n",
    "\n",
    "dataList = []\n",
    "obsList = []\n",
    "\n",
    "for i, d in enumerate(dataset.train_data):\n",
    "    d_tensor = Variable(torch.from_numpy(d).float(), requires_grad=False)\n",
    "    dataList.append({\"k\": d_tensor})\n",
    "\n",
    "    \n",
    "with open(\"data/evidence_train.txt\", 'r') as f:\n",
    "    obsList = f.read().strip().strip(\"#evidence\").split(\"#evidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = []\n",
    "testObsLost = []\n",
    "\n",
    "for d in dataset.test_data:\n",
    "    d_tensor = Variable(torch.from_numpy(d).float(), requires_grad=False)\n",
    "    testData.append({\"k\": d_tensor})\n",
    "    \n",
    "\n",
    "with open(\"data/evidence_test.txt\", 'r') as f:\n",
    "    testObsLost = f.read().strip().strip(\"#evidence\").split(\"#evidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 1 ...\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "\tdlpmlnObj.learn(dataList = dataList, obsList = obsList, epoch=1, opt=True, storeSM=True)\n",
    "\tdlpmlnObj.testConstraint(testData, testObsLost,[dprogram_test])\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
