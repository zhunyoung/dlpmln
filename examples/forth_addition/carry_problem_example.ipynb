{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forth Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../\")\n",
    "from dlpmln import DeepLPMLN\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "from data_function import create_data_sample,format_dataList,format_observations,add_test,carry_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dprogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the DeepLPMLN program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprogram='''\n",
    "num1(1,num1_1).\n",
    "num1(0,num1_0).\n",
    "num2(1,num2_1).\n",
    "num2(0,num2_0).\n",
    "1{carry(0,Carry): Carry=0..1}1.\n",
    "nn(m1(A, B, Carry, 1), result, [0,1,2,3,4,5,6,7,8,9]) :- num1(P,A), num2(P,B), Carry=0..1.\n",
    "nn(m2(A, B, Carry, 1), carry, [0,1]) :- num1(P,A), num2(P,B), Carry=0..1.\n",
    "\n",
    "result(P,X) :- num1(P, A), num2(P, B), carry(P, Carry), result(A,B,Carry,0,X).\n",
    "carry(P+1,X) :- num1(P, A), num2(P, B), carry(P, Carry), carry(A,B,Carry,0,X).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the neural network class that will be used for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "\n",
    "    def __init__(self, *sizes):\n",
    "        super(FC, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(sizes)-2):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
    "        layers.append(nn.Softmax(1))\n",
    "        self.nn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Instantiation\n",
    "- Instantiate neural networks.\n",
    "- Map neural networks into the NNMapping function called 'function'.\n",
    "- Specify the optimizers for each network (we use the Adam optimizer here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = FC(30,25,10) # network for adding the numbers\n",
    "m2 = FC(30,5,2)   # network for finding the carry out\n",
    "\n",
    "\n",
    "functions = {'m1':m1, 'm2':m2} #NNMapping\n",
    "\n",
    "optimizers = {'m1':torch.optim.Adam(m1.parameters(), lr=0.01),'m2':torch.optim.Adam(m2.parameters(), lr=0.01)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are 20 samples of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add([2,9],[2,5],0,[0,5,4]).\n",
      "add([0,1],[7,9],1,[0,8,1]).\n",
      "add([3,1],[1,9],1,[0,5,1]).\n",
      "add([8,5],[2,6],0,[1,1,1]).\n",
      "add([1,9],[4,5],0,[0,6,4]).\n",
      "add([5,8],[6,7],0,[1,2,5]).\n",
      "add([6,2],[8,3],0,[1,4,5]).\n",
      "add([7,1],[2,2],1,[0,9,4]).\n",
      "add([8,9],[4,7],1,[1,3,7]).\n",
      "add([9,2],[2,8],1,[1,2,1]).\n",
      "add([3,3],[3,1],0,[0,6,4]).\n",
      "add([6,5],[4,0],1,[1,0,6]).\n",
      "add([5,7],[8,2],0,[1,3,9]).\n",
      "add([3,3],[4,9],0,[0,8,2]).\n",
      "add([7,0],[9,4],1,[1,6,5]).\n",
      "add([4,8],[7,5],0,[1,2,3]).\n",
      "add([2,3],[6,2],0,[0,8,5]).\n",
      "add([4,6],[5,1],1,[0,9,8]).\n",
      "add([1,6],[5,2],0,[0,6,8]).\n",
      "add([3,9],[6,7],1,[1,0,7]).\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(create_data_sample()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "add([6,7],[8,4],1,[1,5,2]).\n",
      "\n",
      "\n",
      "{'num1_0,num2_0,0': tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'num1_0,num2_0,1': tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'num1_1,num2_1,0': tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'num1_1,num2_1,1': tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])}\n",
      "\n",
      "    :-not carry(0,1).\n",
      "    :-not carry(2,1).\n",
      "    :-not result(1,5).\n",
      "    :-not result(0,2).\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n')\n",
    "\n",
    "obs,str_list=create_data_sample() #data sample the same as DeepProbLog used \n",
    "print(obs+'\\n\\n')\n",
    "\n",
    "dl=format_dataList(obs,str_list) # dataList item\n",
    "print(dl)\n",
    "\n",
    "o=format_observations(obs,str_list) # obsList item\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataList and obsList \n",
    "\n",
    "This the code that will use format_dataList() and format_observations() to build the data set that our DeepLPMLN object will train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = []\n",
    "obsList = []\n",
    "\n",
    "train_size=500\n",
    "test_size=500\n",
    "\n",
    "\n",
    "for i in range(train_size):\n",
    "    \n",
    "    obs,str_list=create_data_sample()\n",
    "    \n",
    "    dataList.append(format_dataList(obs,str_list))\n",
    "    obsList.append(format_observations(obs,str_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test dataset and dataLoader for neural network \"m1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_test_dataset=add_test(test_size)\n",
    "\n",
    "add_test_dataloader=DataLoader(add_test_dataset,batch_size=4,shuffle=True)\n",
    "\n",
    "carry_test_dataset=carry_test(test_size)\n",
    "\n",
    "carry_test_dataloader=DataLoader(carry_test_dataset,batch_size=4,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DeepLPMLN object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlpmlnObj = DeepLPMLN(dprogram, functions, optimizers, dynamicMVPP=False)\n",
    "#dlpmlnObj.device='cpu' #put the training on the CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 21%\n",
      "Test Accuracy on NN Only for m2: 93%\n",
      "--- train time: 59.55068755149841 seconds ---\n",
      "--- test time: 0.1405956745147705 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 42%\n",
      "Test Accuracy on NN Only for m2: 94%\n",
      "--- train time: 59.649752616882324 seconds ---\n",
      "--- test time: 0.1411747932434082 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 64%\n",
      "Test Accuracy on NN Only for m2: 95%\n",
      "--- train time: 59.609055042266846 seconds ---\n",
      "--- test time: 0.14249491691589355 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 70%\n",
      "Test Accuracy on NN Only for m2: 94%\n",
      "--- train time: 59.77775168418884 seconds ---\n",
      "--- test time: 0.14168334007263184 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 82%\n",
      "Test Accuracy on NN Only for m2: 96%\n",
      "--- train time: 60.18323612213135 seconds ---\n",
      "--- test time: 0.1432783603668213 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 86%\n",
      "Test Accuracy on NN Only for m2: 98%\n",
      "--- train time: 60.29462194442749 seconds ---\n",
      "--- test time: 0.14162158966064453 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 88%\n",
      "Test Accuracy on NN Only for m2: 99%\n",
      "--- train time: 60.37051606178284 seconds ---\n",
      "--- test time: 0.15057826042175293 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 90%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 60.08548879623413 seconds ---\n",
      "--- test time: 0.14162278175354004 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 92%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 59.733957290649414 seconds ---\n",
      "--- test time: 0.14111042022705078 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 93%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 60.249754905700684 seconds ---\n",
      "--- test time: 0.14815044403076172 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 94%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 59.79024577140808 seconds ---\n",
      "--- test time: 0.14165329933166504 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 95%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 59.797080516815186 seconds ---\n",
      "--- test time: 0.1406235694885254 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 94%\n",
      "Test Accuracy on NN Only for m2: 99%\n",
      "--- train time: 59.62079215049744 seconds ---\n",
      "--- test time: 0.1418159008026123 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 96%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 60.12959003448486 seconds ---\n",
      "--- test time: 0.14683771133422852 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 96%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 61.75810122489929 seconds ---\n",
      "--- test time: 0.15762901306152344 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 97%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 60.30069351196289 seconds ---\n",
      "--- test time: 0.1576070785522461 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 96%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 60.351600885391235 seconds ---\n",
      "--- test time: 0.1405947208404541 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 96%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 59.61650729179382 seconds ---\n",
      "--- test time: 0.1442253589630127 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 98%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 60.05729675292969 seconds ---\n",
      "--- test time: 0.13814496994018555 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 100%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 60.08133316040039 seconds ---\n",
      "--- test time: 0.1405961513519287 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 99%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 59.93365406990051 seconds ---\n",
      "--- test time: 0.13965845108032227 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 100%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 60.207213163375854 seconds ---\n",
      "--- test time: 0.1435849666595459 seconds ---\n",
      "Training for epoch 1 ...\n",
      "Test Accuracy on NN Only for m1: 100%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 59.92013669013977 seconds ---\n",
      "--- test time: 0.14164495468139648 seconds ---\n",
      "Training for epoch 1 ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-dece4cac6946>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtime1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdlpmlnObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobsList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobsList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtime2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdlpmlnObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtestNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"m1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_test_dataloader\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#test m1 network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\dlpmln\\dlpmln.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, dataList, obsList, epoch, opt, storeSM, mvpplr)\u001b[0m\n\u001b[0;32m    251\u001b[0m                         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdmvpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmvppLearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m                     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdmvpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients_one_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobsList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataIdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[1;31m# Step 4: update parameters in neural networks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\dlpmln\\klpmln.py\u001b[0m in \u001b[0;36mgradients_one_obs\u001b[1;34m(self, obs, opt)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;31m# print('models:\\n{}'.format(models))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# print('program:\\n{}'.format(self.pi_prime))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmvppLearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;31m# gradients are stored in numpy array instead of list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\dlpmln\\klpmln.py\u001b[0m in \u001b[0;36mmvppLearn\u001b[1;34m(self, models)\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;31m# we compute the gradients w.r.t. the probs in each rule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mruleIdx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist_of_bools\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearnable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m             \u001b[0mgradients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mruleIdx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmvppLearnRule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mruleIdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0matomIdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_bools\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\dlpmln\\klpmln.py\u001b[0m in \u001b[0;36mmvppLearnRule\u001b[1;34m(self, ruleIdx, models, probs)\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;31m# if I does not satisfy cEqualsVi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0matomIdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matom\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mruleIdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0matom\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mruleIdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matomIdx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('training...')\n",
    "\n",
    "for i in range(40):\n",
    "    time1 = time.time()\n",
    "    dlpmlnObj.learn(dataList=dataList, obsList=obsList, epoch=1)\n",
    "    time2 = time.time()\n",
    "    dlpmlnObj.testNN(\"m1\", add_test_dataloader) #test m1 network\n",
    "    dlpmlnObj.testNN(\"m2\", carry_test_dataloader) #test m2 network\n",
    "    print(\"--- train time: %s seconds ---\" % (time2 - time1))\n",
    "    print(\"--- test time: %s seconds ---\" % (time.time() - time2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
