{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forth Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forth addition problem is another example used in (Manhaeve et al. 2018) to illustrate DeepProbLogâ€™s ability to do both logical reasoning and deep learning. The task is, given\n",
    "\n",
    "(i) a pair of list of digits, e.g.,\n",
    "\n",
    "    [8, 4] and [5, 2]\n",
    "\n",
    "(ii) a carry-in, e.g., \n",
    "\n",
    "    1\n",
    "\n",
    "and (iii) a list of digits denoting their addition, e.g., (84+52+1=137)\n",
    "\n",
    "    [1, 3, 7]\n",
    "\n",
    "train the neural network m1 to predict the result at each location (e.g., 7 at the unit digit) and train the neural network m2 to predict the carry-out at each location (e.g., 0 at the unit digit) using the 2 digits and the carry-in (e.g., 4, 2, and 1 at the unit digit) at that location as input. Note that the 3 numbers 4, 2, and 1 are turned into the following vector of length 30 before feeding into the neural networks.\n",
    "\n",
    "    [  00001 00000\n",
    "       00100 00000\n",
    "       01000 00000  ]\n",
    "\n",
    "In the above example, the label for neural network m1 is 7 while the label for neural network m2 is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format\n",
    "Below are 20 samples of data following the data format used in DeepProbLog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add([6,1],[8,8],0,[1,4,9]).\n",
      "add([1,1],[0,8],1,[0,2,0]).\n",
      "add([4,7],[9,5],0,[1,4,2]).\n",
      "add([9,9],[6,3],0,[1,6,2]).\n",
      "add([5,1],[4,0],1,[0,9,2]).\n",
      "add([2,4],[9,3],0,[1,1,7]).\n",
      "add([4,9],[4,5],0,[0,9,4]).\n",
      "add([7,9],[5,3],1,[1,3,3]).\n",
      "add([6,7],[1,3],0,[0,8,0]).\n",
      "add([5,9],[1,7],1,[0,7,7]).\n",
      "add([4,7],[5,7],0,[1,0,4]).\n",
      "add([3,7],[0,3],1,[0,4,1]).\n",
      "add([4,7],[6,8],0,[1,1,5]).\n",
      "add([4,9],[5,7],1,[1,0,7]).\n",
      "add([8,3],[4,6],1,[1,3,0]).\n",
      "add([4,1],[1,3],0,[0,5,4]).\n",
      "add([1,7],[0,7],1,[0,2,5]).\n",
      "add([3,6],[1,9],0,[0,5,5]).\n",
      "add([0,0],[5,1],0,[0,5,1]).\n",
      "add([6,8],[1,0],1,[0,7,9]).\n"
     ]
    }
   ],
   "source": [
    "from dataGen import create_data_sample, format_dataList, format_observations\n",
    "for i in range(20):\n",
    "    print(create_data_sample()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the following sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data:\n",
      "add([6,7],[8,5],0,[1,5,2]).\n",
      "\n",
      "This sample data will be turned into the following dictionary (an element in dataList)\n",
      "{'num1_0,num2_0,0': tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'num1_0,num2_0,1': tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'num1_1,num2_1,0': tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'num1_1,num2_1,1': tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])}\n",
      "\n",
      "This sample data will be also turned into the following string (an element in obsList)\n",
      "\n",
      "    :-not carry(0,0).\n",
      "    :-not carry(2,1).\n",
      "    :-not result(1,5).\n",
      "    :-not result(0,2).\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "obs,str_list = create_data_sample()\n",
    "print('Sample data:')\n",
    "print(obs)\n",
    "print('\\nThis sample data will be turned into the following dictionary (an element in dataList)')\n",
    "print(format_dataList(obs,str_list))\n",
    "print('\\nThis sample data will be also turned into the following string (an element in obsList)')\n",
    "print(format_observations(obs,str_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from dataGen import dataList, obsList, add_test_dataloader, carry_test_dataloader\n",
    "from dlpmln import DeepLPMLN\n",
    "from network import FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLPMLN Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprogram='''\n",
    "num1(1,num1_1).\n",
    "num1(0,num1_0).\n",
    "num2(1,num2_1).\n",
    "num2(0,num2_0).\n",
    "1{carry(0,Carry): Carry=0..1}1.\n",
    "\n",
    "nn(m1(A, B, Carry, 1), result, [0,1,2,3,4,5,6,7,8,9]) :- num1(P,A), num2(P,B), Carry=0..1.\n",
    "nn(m2(A, B, Carry, 1), carry, [0,1]) :- num1(P,A), num2(P,B), Carry=0..1.\n",
    "\n",
    "\n",
    "%The first argument of carry/2 and result/2 is the location and the second argument is the value. \n",
    "\n",
    "result(P,X) :- num1(P, A), num2(P, B), carry(P, Carry), result(A,B,Carry,0,X).\n",
    "carry(P+1,X) :- num1(P, A), num2(P, B), carry(P, Carry), carry(A,B,Carry,0,X).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Instantiation\n",
    "- Instantiate neural networks.\n",
    "- Define nnMapping: a dictionary that maps neural network names (i.e., strings) to the neural network objects (i.e., torch.nn.Module object)\n",
    "- Define optimizers: a dictionary that specifies the optimizer for each network (we use the Adam optimizer here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = FC(30,25,10) # network for adding the numbers\n",
    "m2 = FC(30,5,2)   # network for finding the carry out \n",
    "\n",
    "nnMapping = {'m1':m1, 'm2':m2}\n",
    "optimizers = {'m1':torch.optim.Adam(m1.parameters(), lr=0.01),'m2':torch.optim.Adam(m2.parameters(), lr=0.01)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DeepLPMLN Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlpmlnObj = DeepLPMLN(dprogram, nnMapping, optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1...\n",
      "Test Accuracy on NN Only for m1: 43%\n",
      "Test Accuracy on NN Only for m2: 95%\n",
      "--- train time: 139.4350049495697 seconds ---\n",
      "--- test time: 0.011136054992675781 seconds ---\n",
      "--- total time from beginning: 2 minutes ---\n",
      "Epoch 2...\n",
      "Test Accuracy on NN Only for m1: 85%\n",
      "Test Accuracy on NN Only for m2: 98%\n",
      "--- train time: 138.66707825660706 seconds ---\n",
      "--- test time: 0.008195638656616211 seconds ---\n",
      "--- total time from beginning: 4 minutes ---\n",
      "Epoch 3...\n",
      "Test Accuracy on NN Only for m1: 97%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 137.17292094230652 seconds ---\n",
      "--- test time: 0.0081939697265625 seconds ---\n",
      "--- total time from beginning: 6 minutes ---\n",
      "Epoch 4...\n",
      "Test Accuracy on NN Only for m1: 99%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 136.48796391487122 seconds ---\n",
      "--- test time: 0.008369922637939453 seconds ---\n",
      "--- total time from beginning: 9 minutes ---\n",
      "Epoch 5...\n",
      "Test Accuracy on NN Only for m1: 99%\n",
      "Test Accuracy on NN Only for m2: 100%\n",
      "--- train time: 140.3460419178009 seconds ---\n",
      "--- test time: 0.008340835571289062 seconds ---\n",
      "--- total time from beginning: 11 minutes ---\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "for i in range(5):\n",
    "    print('Epoch {}...'.format(i+1))\n",
    "    time1 = time.time()\n",
    "    dlpmlnObj.learn(dataList=dataList, obsList=obsList, epoch=1)\n",
    "    time2 = time.time()\n",
    "    dlpmlnObj.testNN(\"m1\", add_test_dataloader) #test m1 network\n",
    "    dlpmlnObj.testNN(\"m2\", carry_test_dataloader) #test m2 network\n",
    "    print(\"--- train time: %s seconds ---\" % (time2 - time1))\n",
    "    print(\"--- test time: %s seconds ---\" % (time.time() - time2))\n",
    "    print('--- total time from beginning: %s minutes ---' % int((time.time() - startTime)/60) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
