{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forth Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../\")\n",
    "from dlpmln import DeepLPMLN\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "from dataGen import create_data_sample,format_dataList,format_observations,add_test,carry_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dprogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the DeepLPMLN program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprogram='''\n",
    "num1(1,num1_1).\n",
    "num1(0,num1_0).\n",
    "num2(1,num2_1).\n",
    "num2(0,num2_0).\n",
    "1{carry(0,Carry): Carry=0..1}1.\n",
    "nn(m1(A, B, Carry, 1), result, [0,1,2,3,4,5,6,7,8,9]) :- num1(P,A), num2(P,B), Carry=0..1.\n",
    "nn(m2(A, B, Carry, 1), carry, [0,1]) :- num1(P,A), num2(P,B), Carry=0..1.\n",
    "\n",
    "result(P,X) :- num1(P, A), num2(P, B), carry(P, Carry), result(A,B,Carry,0,X).\n",
    "carry(P+1,X) :- num1(P, A), num2(P, B), carry(P, Carry), carry(A,B,Carry,0,X).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the neural network class that will be used for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "\n",
    "    def __init__(self, *sizes):\n",
    "        super(FC, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(sizes)-2):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
    "        layers.append(nn.Softmax(1))\n",
    "        self.nn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Instantiation\n",
    "- Instantiate neural networks.\n",
    "- Map neural networks into the NNMapping function called 'function'.\n",
    "- Specify the optimizers for each network (we use the Adam optimizer here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = FC(30,25,10) # network for adding the numbers\n",
    "m2 = FC(30,5,2)   # network for finding the carry out\n",
    "\n",
    "\n",
    "functions = {'m1':m1, 'm2':m2} #NNMapping\n",
    "\n",
    "optimizers = {'m1':torch.optim.Adam(m1.parameters(), lr=0.01),'m2':torch.optim.Adam(m2.parameters(), lr=0.01)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are 20 samples of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add([4,8],[7,9],1,[1,2,8]).\n",
      "add([4,5],[6,8],1,[1,1,4]).\n",
      "add([1,1],[0,4],0,[0,1,5]).\n",
      "add([5,2],[8,8],1,[1,4,1]).\n",
      "add([6,7],[1,3],0,[0,8,0]).\n",
      "add([7,8],[3,0],0,[1,0,8]).\n",
      "add([9,5],[3,0],1,[1,2,6]).\n",
      "add([0,6],[3,3],1,[0,4,0]).\n",
      "add([5,6],[3,4],0,[0,9,0]).\n",
      "add([9,0],[6,9],0,[1,5,9]).\n",
      "add([1,8],[1,0],1,[0,2,9]).\n",
      "add([2,1],[5,8],1,[0,8,0]).\n",
      "add([1,2],[5,3],0,[0,6,5]).\n",
      "add([7,0],[7,3],0,[1,4,3]).\n",
      "add([4,2],[3,1],0,[0,7,3]).\n",
      "add([6,2],[4,6],1,[1,0,9]).\n",
      "add([9,8],[2,3],0,[1,2,1]).\n",
      "add([0,0],[0,3],1,[0,0,4]).\n",
      "add([2,9],[6,4],1,[0,9,4]).\n",
      "add([6,2],[2,3],0,[0,8,5]).\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(create_data_sample()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "add([2,1],[0,5],0,[0,2,6]).\n",
      "\n",
      "\n",
      "{'num1_0,num2_0,0': tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'num1_0,num2_0,1': tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'num1_1,num2_1,0': tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'num1_1,num2_1,1': tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])}\n",
      "\n",
      "    :-not carry(0,0).\n",
      "    :-not carry(2,0).\n",
      "    :-not result(1,2).\n",
      "    :-not result(0,6).\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n')\n",
    "\n",
    "obs,str_list=create_data_sample() #data sample the same as DeepProbLog used \n",
    "print(obs+'\\n\\n')\n",
    "\n",
    "dl=format_dataList(obs,str_list) # dataList item\n",
    "print(dl)\n",
    "\n",
    "o=format_observations(obs,str_list) # obsList item\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataList and obsList \n",
    "\n",
    "This the code that will use format_dataList() and format_observations() to build the data set that our DeepLPMLN object will train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = []\n",
    "obsList = []\n",
    "\n",
    "train_size=512\n",
    "test_size=512\n",
    "\n",
    "\n",
    "for i in range(train_size):\n",
    "    \n",
    "    obs,str_list=create_data_sample()\n",
    "    \n",
    "    dataList.append(format_dataList(obs,str_list))\n",
    "    obsList.append(format_observations(obs,str_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test dataset and dataLoader for neural network \"m1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_test_dataset=add_test(test_size)\n",
    "\n",
    "add_test_dataloader=DataLoader(add_test_dataset,batch_size=4,shuffle=True)\n",
    "\n",
    "carry_test_dataset=carry_test(test_size)\n",
    "\n",
    "carry_test_dataloader=DataLoader(carry_test_dataset,batch_size=4,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DeepLPMLN object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlpmlnObj = DeepLPMLN(dprogram, functions, optimizers, dynamicMVPP=False)\n",
    "#dlpmlnObj.device='cpu' #put the training on the CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Training for epoch 1 ...\n"
     ]
    }
   ],
   "source": [
    "print('training...')\n",
    "\n",
    "for i in range(40):\n",
    "    time1 = time.time()\n",
    "    dlpmlnObj.learn(dataList=dataList, obsList=obsList, epoch=1)\n",
    "    time2 = time.time()\n",
    "    dlpmlnObj.testNN(\"m1\", add_test_dataloader) #test m1 network\n",
    "    dlpmlnObj.testNN(\"m2\", carry_test_dataloader) #test m2 network\n",
    "    print(\"--- train time: %s seconds ---\" % (time2 - time1))\n",
    "    print(\"--- test time: %s seconds ---\" % (time.time() - time2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
